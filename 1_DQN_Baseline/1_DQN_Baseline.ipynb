{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJZl8UXG8u7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc66f960-d65a-4f52-8549-9d7a415f7502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (0.11.2)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "\u001b[33mWARNING: gymnasium 1.2.2 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n",
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.12/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.12/dist-packages (from ale-py) (2.0.2)\n",
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from shimmy) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.12/dist-packages (from shimmy) (1.2.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=1.0.0a1->shimmy) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[atari]\n",
        "!pip install gymnasium[accept-rom-license]\n",
        "!pip install ale-py\n",
        "!pip install shimmy\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1_DQN_Baseline.py\n",
        "# Standard Deep Q-Network (Nature 2015) optimized for Demo Run\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gymnasium as gym\n",
        "from collections import deque\n",
        "import cv2\n",
        "import ale_py\n",
        "\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "# --- DEMO SETTINGS ---\n",
        "env_id = 'PongNoFrameskip-v4'\n",
        "seed = 42\n",
        "lr = 0.0001\n",
        "buffer_size = 50000\n",
        "batch_size = 32\n",
        "warm_start = 500\n",
        "train_freq = 4\n",
        "target_q_update_freq = 200\n",
        "reward_gamma = 0.99\n",
        "number_timesteps = 2000   # Short demo run\n",
        "clipnorm = 10.0\n",
        "epsilon_start = 1.0\n",
        "epsilon_end = 0.01\n",
        "epsilon_decay_steps = 2000\n",
        "\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        self.env.reset(**kwargs)\n",
        "        obs, _, terminated, truncated, _ = self.env.step(1)\n",
        "        if terminated or truncated: self.env.reset(**kwargs)\n",
        "        obs, _, terminated, truncated, _ = self.env.step(2)\n",
        "        if terminated or truncated: self.env.reset(**kwargs)\n",
        "        return obs, {}\n",
        "\n",
        "class ProcessFrame84(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
        "    def observation(self, obs):\n",
        "        return ProcessFrame84.process(obs)\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "        if frame.size == 210 * 160 * 3: img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
        "        elif frame.size == 250 * 160 * 3: img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
        "        else: return frame\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
        "        resized_screen = cv2.resize(img, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "        x_t = np.reshape(resized_screen, [84, 84, 1])\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "class FrameStack(gym.Wrapper):\n",
        "    def __init__(self, env, k):\n",
        "        super().__init__(env)\n",
        "        self.k = k\n",
        "        self.frames = deque([], maxlen=k)\n",
        "        shp = env.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(shp[0], shp[1], shp[2] * k), dtype=env.observation_space.dtype)\n",
        "    def reset(self, **kwargs):\n",
        "        ob, info = self.env.reset(**kwargs)\n",
        "        for _ in range(self.k): self.frames.append(ob)\n",
        "        return self._get_ob(), info\n",
        "    def step(self, action):\n",
        "        ob, reward, terminated, truncated, info = self.env.step(action)\n",
        "        self.frames.append(ob)\n",
        "        return self._get_ob(), reward, terminated, truncated, info\n",
        "    def _get_ob(self):\n",
        "        assert len(self.frames) == self.k\n",
        "        return np.concatenate(self.frames, axis=2)\n",
        "\n",
        "def build_env(env_id, seed=0):\n",
        "    env = gym.make(env_id, render_mode='rgb_array')\n",
        "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "    env = FireResetEnv(env)\n",
        "    env = ProcessFrame84(env)\n",
        "    env = FrameStack(env, 4)\n",
        "    env.action_space.seed(seed)\n",
        "    return env\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, size):\n",
        "        self.buffer = deque(maxlen=size)\n",
        "    def add(self, obs, act, rew, next_obs, done):\n",
        "        obs = np.array(obs, dtype=np.uint8)\n",
        "        next_obs = np.array(next_obs, dtype=np.uint8)\n",
        "        self.buffer.append((obs, act, rew, next_obs, done))\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        obs, act, rew, next_obs, done = zip(*batch)\n",
        "        return (np.array(obs), np.array(act), np.array(rew, dtype=np.float32), np.array(next_obs), np.array(done, dtype=np.float32))\n",
        "\n",
        "def sync(model, target_model):\n",
        "    target_model.set_weights(model.get_weights())\n",
        "def huber_loss(x):\n",
        "    return tf.keras.losses.Huber()(tf.zeros_like(x), x)\n",
        "def epsilon(step):\n",
        "    if step > epsilon_decay_steps: return epsilon_end\n",
        "    else: return epsilon_start - (epsilon_start - epsilon_end) * (step / epsilon_decay_steps)\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Network Architecture\n",
        "class QFunc(tf.keras.Model):\n",
        "    def __init__(self, name, action_dim):\n",
        "        super(QFunc, self).__init__(name=name)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(32, (8, 8), strides=(4, 4), padding='valid', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='valid', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding='valid', activation='relu')\n",
        "        self.flat = tf.keras.layers.Flatten()\n",
        "        self.fc1 = tf.keras.layers.Dense(512, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(action_dim, activation='linear')\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, pixels, **kwargs):\n",
        "        pixels = tf.divide(tf.cast(pixels, tf.float32), tf.constant(255.0))\n",
        "        if len(pixels.shape) == 4 and pixels.shape[1] == 4: pixels = tf.transpose(pixels, perm=[0, 2, 3, 1])\n",
        "        feature = self.flat(self.conv3(self.conv2(self.conv1(pixels))))\n",
        "        return self.fc2(self.fc1(feature))\n",
        "\n",
        "class DQN(object):\n",
        "    def __init__(self, action_dim):\n",
        "        self.action_dim = action_dim\n",
        "        self.qnet = QFunc('q', action_dim)\n",
        "        self.targetqnet = QFunc('targetq', action_dim)\n",
        "        dummy_obs = tf.zeros((1, 84, 84, 4))\n",
        "        self.qnet(dummy_obs); self.targetqnet(dummy_obs)\n",
        "        sync(self.qnet, self.targetqnet)\n",
        "        self.niter = 0\n",
        "        self.optimizer = tf.optimizers.Adam(learning_rate=lr, epsilon=1e-5, clipnorm=clipnorm)\n",
        "\n",
        "    def get_action(self, obv):\n",
        "        if random.random() < epsilon(self.niter): return int(random.random() * self.action_dim)\n",
        "        else:\n",
        "            obv = np.expand_dims(obv, 0).astype('float32')\n",
        "            return self._qvalues_func(obv).numpy().argmax(1)[0]\n",
        "\n",
        "    @tf.function\n",
        "    def _qvalues_func(self, obv): return self.qnet(obv)\n",
        "\n",
        "    def train(self, b_o, b_a, b_r, b_o_, b_d):\n",
        "        self._train_func(b_o, b_a, b_r, b_o_, b_d)\n",
        "        self.niter += 1\n",
        "        if self.niter % target_q_update_freq == 0: sync(self.qnet, self.targetqnet)\n",
        "\n",
        "    @tf.function\n",
        "    def _train_func(self, b_o, b_a, b_r, b_o_, b_d):\n",
        "        with tf.GradientTape() as tape:\n",
        "            b_a_ = tf.one_hot(tf.argmax(self.qnet(b_o_), 1), self.action_dim)\n",
        "            # Vanilla DQN difference: Max over target network directly\n",
        "            b_q_next = tf.reduce_max(self.targetqnet(b_o_), axis=1)\n",
        "            target_q = b_r + (1 - b_d) * reward_gamma * b_q_next\n",
        "\n",
        "            b_q = tf.reduce_sum(self.qnet(b_o) * tf.one_hot(b_a, self.action_dim), 1)\n",
        "            loss = tf.reduce_mean(huber_loss(target_q - b_q))\n",
        "\n",
        "        grad = tape.gradient(loss, self.qnet.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad, self.qnet.trainable_weights))\n",
        "        return loss\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(f\"Creating environment {env_id}...\")\n",
        "    try: env = build_env(env_id, seed=seed)\n",
        "    except: env = build_env('Pong-v4', seed=seed)\n",
        "\n",
        "    dqn = DQN(env.action_space.n)\n",
        "    buffer = ReplayBuffer(buffer_size)\n",
        "    o, _ = env.reset()\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(\"Starting DQN Baseline Training...\")\n",
        "    for i in range(1, number_timesteps + 1):\n",
        "        a = dqn.get_action(o)\n",
        "        o_, r, terminated, truncated, info = env.step(a)\n",
        "        done = terminated or truncated\n",
        "        buffer.add(o, a, r, o_, done)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "             print(f\"Step: {i} / {number_timesteps} - Epsilon: {epsilon(i):.3f}\")\n",
        "\n",
        "        if i >= warm_start and i % train_freq == 0:\n",
        "            transitions = buffer.sample(batch_size)\n",
        "            dqn.train(*transitions)\n",
        "\n",
        "        if done:\n",
        "            o, _ = env.reset()\n",
        "        else:\n",
        "            o = o_\n",
        "\n",
        "    print(\"DQN Baseline Finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2QcATZN_p0M",
        "outputId": "ee2b7abd-883d-4afa-beb1-9f4abf7c9eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment PongNoFrameskip-v4...\n",
            "Starting DQN Baseline Training...\n",
            "Step: 100 / 2000 - Epsilon: 0.951\n",
            "Step: 200 / 2000 - Epsilon: 0.901\n",
            "Step: 300 / 2000 - Epsilon: 0.852\n",
            "Step: 400 / 2000 - Epsilon: 0.802\n",
            "Step: 500 / 2000 - Epsilon: 0.752\n",
            "Step: 600 / 2000 - Epsilon: 0.703\n",
            "Step: 700 / 2000 - Epsilon: 0.653\n",
            "Step: 800 / 2000 - Epsilon: 0.604\n",
            "Step: 900 / 2000 - Epsilon: 0.554\n",
            "Step: 1000 / 2000 - Epsilon: 0.505\n",
            "Step: 1100 / 2000 - Epsilon: 0.456\n",
            "Step: 1200 / 2000 - Epsilon: 0.406\n",
            "Step: 1300 / 2000 - Epsilon: 0.357\n",
            "Step: 1400 / 2000 - Epsilon: 0.307\n",
            "Step: 1500 / 2000 - Epsilon: 0.258\n",
            "Step: 1600 / 2000 - Epsilon: 0.208\n",
            "Step: 1700 / 2000 - Epsilon: 0.158\n",
            "Step: 1800 / 2000 - Epsilon: 0.109\n",
            "Step: 1900 / 2000 - Epsilon: 0.059\n",
            "Step: 2000 / 2000 - Epsilon: 0.010\n",
            "DQN Baseline Finished.\n"
          ]
        }
      ]
    }
  ]
}