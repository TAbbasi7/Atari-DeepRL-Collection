{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BX6YC2HDKbp",
        "outputId": "d795cfca-dd7a-4c76-ee16-49f15a82b29e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.12/dist-packages (0.11.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n",
            "========================================\n",
            "✅ GPU DETECTED: /physical_device:GPU:0\n",
            "========================================\n",
            "Creating environment PongNoFrameskip-v4...\n",
            "Environment created successfully.\n",
            "Starting training loop...\n",
            "Step: 100 / 2000 - Training in progress... Epsilon: 0.951\n",
            "Step: 200 / 2000 - Training in progress... Epsilon: 0.901\n",
            "Step: 300 / 2000 - Training in progress... Epsilon: 0.852\n",
            "Step: 400 / 2000 - Training in progress... Epsilon: 0.802\n",
            "Step: 500 / 2000 - Training in progress... Epsilon: 0.752\n",
            "Step: 600 / 2000 - Training in progress... Epsilon: 0.703\n",
            "Step: 700 / 2000 - Training in progress... Epsilon: 0.653\n",
            "Step: 800 / 2000 - Training in progress... Epsilon: 0.604\n",
            "Step: 900 / 2000 - Training in progress... Epsilon: 0.554\n",
            "Step: 1000 / 2000 - Training in progress... Epsilon: 0.505\n",
            "Step: 1100 / 2000 - Training in progress... Epsilon: 0.456\n",
            "Step: 1200 / 2000 - Training in progress... Epsilon: 0.406\n",
            "Step: 1300 / 2000 - Training in progress... Epsilon: 0.357\n",
            "Step: 1400 / 2000 - Training in progress... Epsilon: 0.307\n",
            "Step: 1500 / 2000 - Training in progress... Epsilon: 0.258\n",
            "Step: 1600 / 2000 - Training in progress... Epsilon: 0.208\n",
            "Step: 1700 / 2000 - Training in progress... Epsilon: 0.158\n",
            "Step: 1800 / 2000 - Training in progress... Epsilon: 0.109\n",
            "Step: 1900 / 2000 - Training in progress... Epsilon: 0.059\n",
            "Step: 2000 / 2000 - Training in progress... Epsilon: 0.010\n",
            "Training finished successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install gymnasium[atari] ale-py opencv-python tensorflow shimmy\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gymnasium as gym\n",
        "from collections import deque\n",
        "import cv2\n",
        "import ale_py\n",
        "\n",
        "# ثبت محیط‌های آتاری\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "# --- تنظیمات دمو (برای اجرای سریع) ---\n",
        "env_id = 'PongNoFrameskip-v4'\n",
        "seed = 42\n",
        "lr = 0.0001\n",
        "buffer_size = 50000\n",
        "batch_size = 32\n",
        "warm_start = 500          # شروع سریع بعد از ۵۰۰ فریم\n",
        "train_freq = 4\n",
        "target_q_update_freq = 200 # آپدیت سریع‌تر تارگت برای دمو\n",
        "reward_gamma = 0.99\n",
        "number_timesteps = 2000   # کل زمان اجرا فقط ۲۰۰۰ فریم (حدود ۳ دقیقه)\n",
        "clipnorm = 10.0\n",
        "epsilon_start = 1.0\n",
        "epsilon_end = 0.01\n",
        "epsilon_decay_steps = 2000 # کاهش سریع اپسیلون برای دمو\n",
        "\n",
        "# ==========================================\n",
        "\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        self.env.reset(**kwargs)\n",
        "        obs, _, terminated, truncated, _ = self.env.step(1)\n",
        "        if terminated or truncated:\n",
        "            self.env.reset(**kwargs)\n",
        "        obs, _, terminated, truncated, _ = self.env.step(2)\n",
        "        if terminated or truncated:\n",
        "            self.env.reset(**kwargs)\n",
        "        return obs, {}\n",
        "\n",
        "class ProcessFrame84(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0, high=255, shape=(84, 84, 1), dtype=np.uint8\n",
        "        )\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return ProcessFrame84.process(obs)\n",
        "\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "        if frame.size == 210 * 160 * 3:\n",
        "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
        "        elif frame.size == 250 * 160 * 3:\n",
        "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
        "        else:\n",
        "            return frame\n",
        "\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
        "        resized_screen = cv2.resize(img, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "        x_t = np.reshape(resized_screen, [84, 84, 1])\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "class FrameStack(gym.Wrapper):\n",
        "    def __init__(self, env, k):\n",
        "        super().__init__(env)\n",
        "        self.k = k\n",
        "        self.frames = deque([], maxlen=k)\n",
        "        shp = env.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0, high=255,\n",
        "            shape=(shp[0], shp[1], shp[2] * k),\n",
        "            dtype=env.observation_space.dtype\n",
        "        )\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        ob, info = self.env.reset(**kwargs)\n",
        "        for _ in range(self.k):\n",
        "            self.frames.append(ob)\n",
        "        return self._get_ob(), info\n",
        "\n",
        "    def step(self, action):\n",
        "        ob, reward, terminated, truncated, info = self.env.step(action)\n",
        "        self.frames.append(ob)\n",
        "        return self._get_ob(), reward, terminated, truncated, info\n",
        "\n",
        "    def _get_ob(self):\n",
        "        assert len(self.frames) == self.k\n",
        "        return np.concatenate(self.frames, axis=2)\n",
        "\n",
        "print(\"=\"*40)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"✅ GPU DETECTED: {gpus[0].name}\")\n",
        "else:\n",
        "    print(\"❌ GPU NOT FOUND. Please enable T4 GPU in Runtime settings.\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "def build_env(env_id, seed=0):\n",
        "    env = gym.make(env_id, render_mode='rgb_array')\n",
        "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "    env = FireResetEnv(env)\n",
        "    env = ProcessFrame84(env)\n",
        "    env = FrameStack(env, 4)\n",
        "    env.action_space.seed(seed)\n",
        "    return env\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, size):\n",
        "        self.buffer = deque(maxlen=size)\n",
        "\n",
        "    def add(self, obs, act, rew, next_obs, done):\n",
        "        obs = np.array(obs, dtype=np.uint8)\n",
        "        next_obs = np.array(next_obs, dtype=np.uint8)\n",
        "        self.buffer.append((obs, act, rew, next_obs, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        obs, act, rew, next_obs, done = zip(*batch)\n",
        "        return (np.array(obs), np.array(act), np.array(rew, dtype=np.float32),\n",
        "                np.array(next_obs), np.array(done, dtype=np.float32))\n",
        "\n",
        "def sync(model, target_model):\n",
        "    target_model.set_weights(model.get_weights())\n",
        "\n",
        "def huber_loss(x):\n",
        "    return tf.keras.losses.Huber()(tf.zeros_like(x), x)\n",
        "\n",
        "def epsilon(step):\n",
        "    if step > epsilon_decay_steps:\n",
        "        return epsilon_end\n",
        "    else:\n",
        "        diff = epsilon_start - epsilon_end\n",
        "        return epsilon_start - diff * (step / epsilon_decay_steps)\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "print(f\"Creating environment {env_id}...\")\n",
        "try:\n",
        "    env = build_env(env_id, seed=seed)\n",
        "    print(\"Environment created successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating env: {e}\")\n",
        "    print(\"Trying generic Pong-v4...\")\n",
        "    env = build_env('Pong-v4', seed=seed)\n",
        "\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "class QFunc(tf.keras.Model):\n",
        "    def __init__(self, name):\n",
        "        super(QFunc, self).__init__(name=name)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(32, (8, 8), strides=(4, 4), padding='valid', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='valid', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding='valid', activation='relu')\n",
        "        self.flat = tf.keras.layers.Flatten()\n",
        "        self.fc1 = tf.keras.layers.Dense(512, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(action_dim, activation='linear')\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, pixels, **kwargs):\n",
        "        pixels = tf.divide(tf.cast(pixels, tf.float32), tf.constant(255.0))\n",
        "        if len(pixels.shape) == 4 and pixels.shape[1] == 4: # NCHW\n",
        "             pixels = tf.transpose(pixels, perm=[0, 2, 3, 1]) # -> NHWC\n",
        "\n",
        "        feature = self.flat(self.conv3(self.conv2(self.conv1(pixels))))\n",
        "        return self.fc2(self.fc1(feature))\n",
        "\n",
        "class DQN(object):\n",
        "    def __init__(self):\n",
        "        self.qnet = QFunc('q')\n",
        "        self.targetqnet = QFunc('targetq')\n",
        "        dummy_obs = tf.zeros((1, 84, 84, 4))\n",
        "        self.qnet(dummy_obs)\n",
        "        self.targetqnet(dummy_obs)\n",
        "        sync(self.qnet, self.targetqnet)\n",
        "        self.niter = 0\n",
        "        self.optimizer = tf.optimizers.Adam(learning_rate=lr, epsilon=1e-5, clipnorm=clipnorm)\n",
        "\n",
        "    def get_action(self, obv):\n",
        "        eps = epsilon(self.niter)\n",
        "        if random.random() < eps:\n",
        "            return int(random.random() * action_dim)\n",
        "        else:\n",
        "            obv = np.expand_dims(obv, 0).astype('float32')\n",
        "            return self._qvalues_func(obv).numpy().argmax(1)[0]\n",
        "\n",
        "    @tf.function\n",
        "    def _qvalues_func(self, obv):\n",
        "        return self.qnet(obv)\n",
        "\n",
        "    def train(self, b_o, b_a, b_r, b_o_, b_d):\n",
        "        self._train_func(b_o, b_a, b_r, b_o_, b_d)\n",
        "        self.niter += 1\n",
        "        if self.niter % target_q_update_freq == 0:\n",
        "            sync(self.qnet, self.targetqnet)\n",
        "\n",
        "    @tf.function\n",
        "    def _train_func(self, b_o, b_a, b_r, b_o_, b_d):\n",
        "        with tf.GradientTape() as tape:\n",
        "            td_errors = self._tderror_func(b_o, b_a, b_r, b_o_, b_d)\n",
        "            loss = tf.reduce_mean(huber_loss(td_errors))\n",
        "        grad = tape.gradient(loss, self.qnet.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad, self.qnet.trainable_weights))\n",
        "        return td_errors\n",
        "\n",
        "    @tf.function\n",
        "    def _tderror_func(self, b_o, b_a, b_r, b_o_, b_d):\n",
        "        b_a_ = tf.one_hot(tf.argmax(self.qnet(b_o_), 1), action_dim)\n",
        "        b_q_ = (1 - b_d) * tf.reduce_sum(self.targetqnet(b_o_) * b_a_, 1)\n",
        "        b_q = tf.reduce_sum(self.qnet(b_o) * tf.one_hot(b_a, action_dim), 1)\n",
        "        return b_q - (b_r + reward_gamma * b_q_)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"Starting training loop...\")\n",
        "    dqn = DQN()\n",
        "    buffer = ReplayBuffer(buffer_size)\n",
        "\n",
        "    o, _ = env.reset()\n",
        "    nepisode = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(1, number_timesteps + 1):\n",
        "        a = dqn.get_action(o)\n",
        "        o_, r, terminated, truncated, info = env.step(a)\n",
        "        done = terminated or truncated\n",
        "        buffer.add(o, a, r, o_, done)\n",
        "\n",
        "        # === بخش اضافه شده برای نمایش لاگ وسط بازی ===\n",
        "        if i % 100 == 0:\n",
        "             print(f\"Step: {i} / {number_timesteps} - Training in progress... Epsilon: {epsilon(i):.3f}\")\n",
        "        # ============================================\n",
        "\n",
        "        if i >= warm_start and i % train_freq == 0:\n",
        "            transitions = buffer.sample(batch_size)\n",
        "            dqn.train(*transitions)\n",
        "\n",
        "        if done:\n",
        "            o, _ = env.reset()\n",
        "            nepisode += 1\n",
        "            if 'episode' in info:\n",
        "                 reward = info['episode']['r']\n",
        "                 length = info['episode']['l']\n",
        "                 if hasattr(reward, 'numpy'): reward = reward.numpy()\n",
        "                 if hasattr(length, 'numpy'): length = length.numpy()\n",
        "\n",
        "                 elapsed = time.time() - start_time\n",
        "                 print(f'*** EPISODE DONE *** Step: {i}, Episode: {nepisode}, Reward: {reward:.1f}, Len: {length}, Time: {elapsed:.1f}s')\n",
        "            else:\n",
        "                 print(f'Episode {nepisode} finished at step {i}')\n",
        "        else:\n",
        "            o = o_\n",
        "\n",
        "    print(\"Training finished successfully.\")\n"
      ]
    }
  ]
}